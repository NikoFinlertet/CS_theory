# –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã üßÆ

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. [–õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞](#–ª–∏–Ω–µ–π–Ω–∞—è-–∞–ª–≥–µ–±—Ä–∞)
2. [–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å](#—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞-–∏-–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
3. [–î–∏—Å–∫—Ä–µ—Ç–Ω–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞](#–¥–∏—Å–∫—Ä–µ—Ç–Ω–∞—è-–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞)
4. [–¢–µ–æ—Ä–∏—è –≥—Ä–∞—Ñ–æ–≤](#—Ç–µ–æ—Ä–∏—è-–≥—Ä–∞—Ñ–æ–≤)
5. [–ß–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã](#—á–∏—Å–ª–µ–Ω–Ω—ã–µ-–º–µ—Ç–æ–¥—ã)
6. [–¢–µ–æ—Ä–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏](#—Ç–µ–æ—Ä–∏—è-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)

---

## –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞

### –í–µ–∫—Ç–æ—Ä—ã –∏ –º–∞—Ç—Ä–∏—Ü—ã
```python
import numpy as np

class LinearAlgebra:
    """–û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –ª–∏–Ω–µ–π–Ω–æ–π –∞–ª–≥–µ–±—Ä—ã"""
    
    @staticmethod
    def dot_product(a, b):
        """–°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤"""
        return np.sum(a * b)
    
    @staticmethod
    def vector_norm(v, p=2):
        """–ù–æ—Ä–º–∞ –≤–µ–∫—Ç–æ—Ä–∞ (L1, L2, L‚àû)"""
        if p == 1:
            return np.sum(np.abs(v))  # L1 –Ω–æ—Ä–º–∞
        elif p == 2:
            return np.sqrt(np.sum(v**2))  # L2 –Ω–æ—Ä–º–∞ (–ï–≤–∫–ª–∏–¥–æ–≤–∞)
        elif p == float('inf'):
            return np.max(np.abs(v))  # L‚àû –Ω–æ—Ä–º–∞
    
    @staticmethod
    def matrix_multiply(A, B):
        """–£–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü"""
        m, n = A.shape
        n_b, p = B.shape
        
        if n != n_b:
            raise ValueError("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –º–∞—Ç—Ä–∏—Ü –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
        
        C = np.zeros((m, p))
        for i in range(m):
            for j in range(p):
                for k in range(n):
                    C[i, j] += A[i, k] * B[k, j]
        return C
    
    @staticmethod
    def gaussian_elimination(A, b):
        """–†–µ—à–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ª–∏–Ω–µ–π–Ω—ã—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏–π –º–µ—Ç–æ–¥–æ–º –ì–∞—É—Å—Å–∞"""
        n = len(A)
        
        # –ü—Ä—è–º–æ–π —Ö–æ–¥
        for i in range(n):
            # –ü–æ–∏—Å–∫ –≥–ª–∞–≤–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            max_row = i
            for k in range(i + 1, n):
                if abs(A[k][i]) > abs(A[max_row][i]):
                    max_row = k
            
            # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç—Ä–æ–∫
            A[i], A[max_row] = A[max_row], A[i]
            b[i], b[max_row] = b[max_row], b[i]
            
            # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Ç—Ä–µ—É–≥–æ–ª—å–Ω–æ–º—É –≤–∏–¥—É
            for k in range(i + 1, n):
                factor = A[k][i] / A[i][i]
                for j in range(i, n):
                    A[k][j] -= factor * A[i][j]
                b[k] -= factor * b[i]
        
        # –û–±—Ä–∞—Ç–Ω—ã–π —Ö–æ–¥
        x = [0] * n
        for i in range(n - 1, -1, -1):
            x[i] = b[i]
            for j in range(i + 1, n):
                x[i] -= A[i][j] * x[j]
            x[i] /= A[i][i]
        
        return x
    
    @staticmethod
    def eigenvalues_power_method(A, max_iter=1000, tol=1e-6):
        """–ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–º —Å—Ç–µ–ø–µ–Ω–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏"""
        n = A.shape[0]
        v = np.random.rand(n)
        v = v / np.linalg.norm(v)
        
        for _ in range(max_iter):
            v_new = np.dot(A, v)
            eigenvalue = np.dot(v, v_new)
            v_new = v_new / np.linalg.norm(v_new)
            
            if np.linalg.norm(v_new - v) < tol:
                break
            
            v = v_new
        
        return eigenvalue, v
    
    @staticmethod
    def svd_decomposition(A):
        """–°–∏–Ω–≥—É–ª—è—Ä–Ω–æ–µ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        # A = U * Œ£ * V^T
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        U, s, Vt = np.linalg.svd(A)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
        Sigma = np.zeros_like(A)
        min_dim = min(A.shape)
        Sigma[:min_dim, :min_dim] = np.diag(s)
        
        return U, Sigma, Vt
    
    @staticmethod
    def pca_analysis(X, n_components=2):
        """–ê–Ω–∞–ª–∏–∑ –≥–ª–∞–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç"""
        # –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_centered = X - np.mean(X, axis=0)
        
        # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        cov_matrix = np.cov(X_centered.T)
        
        # –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è
        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        indices = np.argsort(eigenvalues)[::-1]
        eigenvalues = eigenvalues[indices]
        eigenvectors = eigenvectors[:, indices]
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ n_components –≥–ª–∞–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        principal_components = eigenvectors[:, :n_components]
        
        # –ü—Ä–æ–µ–∫—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        X_pca = np.dot(X_centered, principal_components)
        
        # –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
        explained_variance_ratio = eigenvalues[:n_components] / np.sum(eigenvalues)
        
        return X_pca, principal_components, explained_variance_ratio

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è PCA
def demonstrate_pca():
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    np.random.seed(42)
    X = np.random.randn(100, 5)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º PCA
    la = LinearAlgebra()
    X_pca, components, variance_ratio = la.pca_analysis(X, n_components=2)
    
    print(f"–ì–ª–∞–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {components.shape}")
    print(f"–û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è: {variance_ratio}")
    print(f"–°—É–º–º–∞ –æ–±—ä—è—Å–Ω–µ–Ω–Ω–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–∏: {np.sum(variance_ratio):.3f}")
```

---

## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å

### –î–µ—Å–∫—Ä–∏–ø—Ç–∏–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
```python
class Statistics:
    """–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏"""
    
    @staticmethod
    def mean(data):
        """–°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ"""
        return sum(data) / len(data)
    
    @staticmethod
    def median(data):
        """–ú–µ–¥–∏–∞–Ω–∞"""
        sorted_data = sorted(data)
        n = len(sorted_data)
        if n % 2 == 0:
            return (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2
        else:
            return sorted_data[n//2]
    
    @staticmethod
    def mode(data):
        """–ú–æ–¥–∞"""
        from collections import Counter
        counts = Counter(data)
        max_count = max(counts.values())
        return [value for value, count in counts.items() if count == max_count]
    
    @staticmethod
    def variance(data, ddof=0):
        """–î–∏—Å–ø–µ—Ä—Å–∏—è"""
        mean_val = Statistics.mean(data)
        return sum((x - mean_val) ** 2 for x in data) / (len(data) - ddof)
    
    @staticmethod
    def standard_deviation(data, ddof=0):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"""
        return np.sqrt(Statistics.variance(data, ddof))
    
    @staticmethod
    def correlation(x, y):
        """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞"""
        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(x[i] ** 2 for i in range(n))
        sum_y2 = sum(y[i] ** 2 for i in range(n))
        
        numerator = n * sum_xy - sum_x * sum_y
        denominator = np.sqrt((n * sum_x2 - sum_x ** 2) * (n * sum_y2 - sum_y ** 2))
        
        if denominator == 0:
            return 0
        
        return numerator / denominator
    
    @staticmethod
    def percentile(data, p):
        """–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å"""
        sorted_data = sorted(data)
        n = len(sorted_data)
        
        if p < 0 or p > 100:
            raise ValueError("–ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 100")
        
        # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
        k = (n - 1) * p / 100
        floor_k = int(k)
        ceil_k = min(floor_k + 1, n - 1)
        
        if floor_k == ceil_k:
            return sorted_data[floor_k]
        
        d = k - floor_k
        return sorted_data[floor_k] * (1 - d) + sorted_data[ceil_k] * d
    
    @staticmethod
    def quartiles(data):
        """–ö–≤–∞—Ä—Ç–∏–ª–∏"""
        return {
            'Q1': Statistics.percentile(data, 25),
            'Q2': Statistics.percentile(data, 50),  # –ú–µ–¥–∏–∞–Ω–∞
            'Q3': Statistics.percentile(data, 75)
        }
    
    @staticmethod
    def outliers_iqr(data):
        """–í—ã–±—Ä–æ—Å—ã –ø–æ –º–µ—Ç–æ–¥—É IQR"""
        q = Statistics.quartiles(data)
        iqr = q['Q3'] - q['Q1']
        lower_bound = q['Q1'] - 1.5 * iqr
        upper_bound = q['Q3'] + 1.5 * iqr
        
        outliers = [x for x in data if x < lower_bound or x > upper_bound]
        return outliers, lower_bound, upper_bound

class ProbabilityDistributions:
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    @staticmethod
    def binomial_probability(n, k, p):
        """–ë–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"""
        from math import comb
        return comb(n, k) * (p ** k) * ((1 - p) ** (n - k))
    
    @staticmethod
    def poisson_probability(k, lambda_param):
        """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ü—É–∞—Å—Å–æ–Ω–∞"""
        from math import factorial, exp
        return (lambda_param ** k) * exp(-lambda_param) / factorial(k)
    
    @staticmethod
    def normal_pdf(x, mu=0, sigma=1):
        """–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)
    
    @staticmethod
    def normal_cdf(x, mu=0, sigma=1):
        """–§—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        return 0.5 * (1 + np.tanh((x - mu) / (sigma * np.sqrt(2))))
    
    @staticmethod
    def confidence_interval(data, confidence_level=0.95):
        """–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ"""
        n = len(data)
        mean = Statistics.mean(data)
        std = Statistics.standard_deviation(data, ddof=1)
        
        # t-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–æ–∫
        from scipy.stats import t
        alpha = 1 - confidence_level
        t_value = t.ppf(1 - alpha/2, n - 1)
        
        margin_error = t_value * std / np.sqrt(n)
        
        return mean - margin_error, mean + margin_error
    
    @staticmethod
    def hypothesis_test_mean(sample, null_hypothesis_mean, alpha=0.05):
        """t-—Ç–µ—Å—Ç –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ"""
        n = len(sample)
        sample_mean = Statistics.mean(sample)
        sample_std = Statistics.standard_deviation(sample, ddof=1)
        
        # t-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        t_stat = (sample_mean - null_hypothesis_mean) / (sample_std / np.sqrt(n))
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        from scipy.stats import t
        t_critical = t.ppf(1 - alpha/2, n - 1)
        
        # p-–∑–Ω–∞—á–µ–Ω–∏–µ
        p_value = 2 * (1 - t.cdf(abs(t_stat), n - 1))
        
        reject_null = abs(t_stat) > t_critical
        
        return {
            't_statistic': t_stat,
            't_critical': t_critical,
            'p_value': p_value,
            'reject_null': reject_null,
            'conclusion': '–û—Ç–≤–µ—Ä–≥–∞–µ–º H0' if reject_null else '–ù–µ –æ—Ç–≤–µ—Ä–≥–∞–µ–º H0'
        }
```

---

## –î–∏—Å–∫—Ä–µ—Ç–Ω–∞—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞

### –ö–æ–º–±–∏–Ω–∞—Ç–æ—Ä–∏–∫–∞
```python
class Combinatorics:
    """–ö–æ–º–±–∏–Ω–∞—Ç–æ—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"""
    
    @staticmethod
    def factorial(n):
        """–§–∞–∫—Ç–æ—Ä–∏–∞–ª"""
        if n < 0:
            raise ValueError("–§–∞–∫—Ç–æ—Ä–∏–∞–ª –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –¥–ª—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª")
        if n == 0 or n == 1:
            return 1
        return n * Combinatorics.factorial(n - 1)
    
    @staticmethod
    def permutations(n, r):
        """–†–∞–∑–º–µ—â–µ–Ω–∏—è P(n,r) = n! / (n-r)!"""
        if r > n or r < 0:
            return 0
        return Combinatorics.factorial(n) // Combinatorics.factorial(n - r)
    
    @staticmethod
    def combinations(n, r):
        """–°–æ—á–µ—Ç–∞–Ω–∏—è C(n,r) = n! / (r!(n-r)!)"""
        if r > n or r < 0:
            return 0
        if r == 0 or r == n:
            return 1
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–µ–µ –∏–∑ r –∏ n-r
        r = min(r, n - r)
        
        result = 1
        for i in range(r):
            result = result * (n - i) // (i + 1)
        
        return result
    
    @staticmethod
    def stirling_second_kind(n, k):
        """–ß–∏—Å–ª–∞ –°—Ç–∏—Ä–ª–∏–Ω–≥–∞ –≤—Ç–æ—Ä–æ–≥–æ —Ä–æ–¥–∞ S(n,k)"""
        if n == 0 and k == 0:
            return 1
        if n == 0 or k == 0:
            return 0
        if k > n:
            return 0
        if k == 1 or k == n:
            return 1
        
        # –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: S(n,k) = k*S(n-1,k) + S(n-1,k-1)
        return k * Combinatorics.stirling_second_kind(n - 1, k) + \
               Combinatorics.stirling_second_kind(n - 1, k - 1)
    
    @staticmethod
    def catalan_number(n):
        """n-–µ —á–∏—Å–ª–æ –ö–∞—Ç–∞–ª–∞–Ω–∞"""
        if n <= 1:
            return 1
        
        # C(n) = (2n)! / ((n+1)! * n!)
        return Combinatorics.combinations(2 * n, n) // (n + 1)
    
    @staticmethod
    def fibonacci(n):
        """n-–µ —á–∏—Å–ª–æ –§–∏–±–æ–Ω–∞—á—á–∏"""
        if n <= 1:
            return n
        
        a, b = 0, 1
        for _ in range(2, n + 1):
            a, b = b, a + b
        
        return b
    
    @staticmethod
    def generate_permutations(items):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ–∫"""
        if len(items) <= 1:
            yield items
        else:
            for i in range(len(items)):
                for perm in Combinatorics.generate_permutations(items[:i] + items[i+1:]):
                    yield [items[i]] + perm
    
    @staticmethod
    def generate_combinations(items, r):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Å–æ—á–µ—Ç–∞–Ω–∏–π —Ä–∞–∑–º–µ—Ä–∞ r"""
        if r == 0:
            yield []
        elif r == len(items):
            yield items
        elif r > len(items):
            return
        else:
            # –í–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
            for combo in Combinatorics.generate_combinations(items[1:], r - 1):
                yield [items[0]] + combo
            
            # –ù–µ –≤–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
            for combo in Combinatorics.generate_combinations(items[1:], r):
                yield combo
    
    @staticmethod
    def generate_subsets(items):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤"""
        n = len(items)
        for i in range(2**n):
            subset = []
            for j in range(n):
                if i & (1 << j):
                    subset.append(items[j])
            yield subset

class SetTheory:
    """–¢–µ–æ—Ä–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤"""
    
    @staticmethod
    def union(set1, set2):
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤"""
        return set1 | set2
    
    @staticmethod
    def intersection(set1, set2):
        """–ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤"""
        return set1 & set2
    
    @staticmethod
    def difference(set1, set2):
        """–†–∞–∑–Ω–æ—Å—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤"""
        return set1 - set2
    
    @staticmethod
    def symmetric_difference(set1, set2):
        """–°–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å"""
        return set1 ^ set2
    
    @staticmethod
    def cartesian_product(set1, set2):
        """–î–µ–∫–∞—Ä—Ç–æ–≤–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ"""
        return {(a, b) for a in set1 for b in set2}
    
    @staticmethod
    def power_set(s):
        """–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—Å–µ—Ö –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤"""
        items = list(s)
        power_set = set()
        
        for subset in Combinatorics.generate_subsets(items):
            power_set.add(frozenset(subset))
        
        return power_set
    
    @staticmethod
    def is_subset(set1, set2):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ"""
        return set1 <= set2
    
    @staticmethod
    def is_superset(set1, set2):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ"""
        return set1 >= set2
```

---

## –¢–µ–æ—Ä–∏—è –≥—Ä–∞—Ñ–æ–≤

### –û—Å–Ω–æ–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–∞ –≥—Ä–∞—Ñ–∞—Ö
```python
from collections import defaultdict, deque

class Graph:
    """–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞"""
    
    def __init__(self, directed=False):
        self.directed = directed
        self.vertices = set()
        self.edges = defaultdict(list)
        self.edge_weights = {}
    
    def add_vertex(self, vertex):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—à–∏–Ω—ã"""
        self.vertices.add(vertex)
    
    def add_edge(self, u, v, weight=1):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–±—Ä–∞"""
        self.vertices.add(u)
        self.vertices.add(v)
        self.edges[u].append(v)
        self.edge_weights[(u, v)] = weight
        
        if not self.directed:
            self.edges[v].append(u)
            self.edge_weights[(v, u)] = weight
    
    def bfs(self, start):
        """–û–±—Ö–æ–¥ –≤ —à–∏—Ä–∏–Ω—É"""
        visited = set()
        queue = deque([start])
        result = []
        
        while queue:
            vertex = queue.popleft()
            if vertex not in visited:
                visited.add(vertex)
                result.append(vertex)
                
                for neighbor in self.edges[vertex]:
                    if neighbor not in visited:
                        queue.append(neighbor)
        
        return result
    
    def dfs(self, start):
        """–û–±—Ö–æ–¥ –≤ –≥–ª—É–±–∏–Ω—É"""
        visited = set()
        result = []
        
        def dfs_recursive(vertex):
            visited.add(vertex)
            result.append(vertex)
            
            for neighbor in self.edges[vertex]:
                if neighbor not in visited:
                    dfs_recursive(neighbor)
        
        dfs_recursive(start)
        return result
    
    def shortest_path_dijkstra(self, start, end):
        """–ê–ª–≥–æ—Ä–∏—Ç–º –î–µ–π–∫—Å—Ç—Ä—ã –¥–ª—è –∫—Ä–∞—Ç—á–∞–π—à–µ–≥–æ –ø—É—Ç–∏"""
        import heapq
        
        distances = {vertex: float('inf') for vertex in self.vertices}
        distances[start] = 0
        previous = {}
        
        pq = [(0, start)]
        
        while pq:
            current_distance, current_vertex = heapq.heappop(pq)
            
            if current_vertex == end:
                break
            
            if current_distance > distances[current_vertex]:
                continue
            
            for neighbor in self.edges[current_vertex]:
                weight = self.edge_weights.get((current_vertex, neighbor), 1)
                distance = current_distance + weight
                
                if distance < distances[neighbor]:
                    distances[neighbor] = distance
                    previous[neighbor] = current_vertex
                    heapq.heappush(pq, (distance, neighbor))
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É—Ç–∏
        path = []
        current = end
        while current is not None:
            path.append(current)
            current = previous.get(current)
        
        path.reverse()
        return path if path[0] == start else None
    
    def minimum_spanning_tree_kruskal(self):
        """–ê–ª–≥–æ—Ä–∏—Ç–º –ö—Ä–∞—Å–∫–∞–ª–∞ –¥–ª—è –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –æ—Å—Ç–æ–≤–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞"""
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–±—Ä–∞
        edges = []
        for u in self.vertices:
            for v in self.edges[u]:
                if not self.directed or u < v:  # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –Ω–µ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≥—Ä–∞—Ñ–µ
                    weight = self.edge_weights.get((u, v), 1)
                    edges.append((weight, u, v))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–±—Ä–∞ –ø–æ –≤–µ—Å—É
        edges.sort()
        
        # –°–∏—Å—Ç–µ–º–∞ –Ω–µ–ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏—Ö—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤
        parent = {}
        rank = {}
        
        def find(x):
            if x not in parent:
                parent[x] = x
                rank[x] = 0
            if parent[x] != x:
                parent[x] = find(parent[x])
            return parent[x]
        
        def union(x, y):
            px, py = find(x), find(y)
            if px == py:
                return False
            if rank[px] < rank[py]:
                px, py = py, px
            parent[py] = px
            if rank[px] == rank[py]:
                rank[px] += 1
            return True
        
        mst = []
        for weight, u, v in edges:
            if union(u, v):
                mst.append((u, v, weight))
        
        return mst
    
    def topological_sort(self):
        """–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞"""
        if not self.directed:
            raise ValueError("–¢–æ–ø–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–æ–≤")
        
        in_degree = {vertex: 0 for vertex in self.vertices}
        
        # –ü–æ–¥—Å—á–µ—Ç –≤—Ö–æ–¥—è—â–∏—Ö —Å—Ç–µ–ø–µ–Ω–µ–π
        for u in self.vertices:
            for v in self.edges[u]:
                in_degree[v] += 1
        
        # –û—á–µ—Ä–µ–¥—å –≤–µ—Ä—à–∏–Ω —Å –Ω—É–ª–µ–≤–æ–π –≤—Ö–æ–¥—è—â–µ–π —Å—Ç–µ–ø–µ–Ω—å—é
        queue = deque([v for v in self.vertices if in_degree[v] == 0])
        result = []
        
        while queue:
            vertex = queue.popleft()
            result.append(vertex)
            
            for neighbor in self.edges[vertex]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)
        
        if len(result) != len(self.vertices):
            raise ValueError("–ì—Ä–∞—Ñ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ü–∏–∫–ª—ã")
        
        return result
    
    def has_cycle(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ü–∏–∫–ª–æ–≤"""
        if not self.directed:
            # –î–ª—è –Ω–µ–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞
            visited = set()
            
            def dfs_undirected(vertex, parent):
                visited.add(vertex)
                for neighbor in self.edges[vertex]:
                    if neighbor not in visited:
                        if dfs_undirected(neighbor, vertex):
                            return True
                    elif neighbor != parent:
                        return True
                return False
            
            for vertex in self.vertices:
                if vertex not in visited:
                    if dfs_undirected(vertex, None):
                        return True
            return False
        else:
            # –î–ª—è –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∞ (–ø–æ–∏—Å–∫ –æ–±—Ä–∞—Ç–Ω—ã—Ö —Ä–µ–±–µ—Ä)
            WHITE, GRAY, BLACK = 0, 1, 2
            color = {vertex: WHITE for vertex in self.vertices}
            
            def dfs_directed(vertex):
                color[vertex] = GRAY
                for neighbor in self.edges[vertex]:
                    if color[neighbor] == GRAY:
                        return True
                    elif color[neighbor] == WHITE and dfs_directed(neighbor):
                        return True
                color[vertex] = BLACK
                return False
            
            for vertex in self.vertices:
                if color[vertex] == WHITE:
                    if dfs_directed(vertex):
                        return True
            return False
    
    def strongly_connected_components(self):
        """–°–∏–ª—å–Ω–æ —Å–≤—è–∑–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–∞–ª–≥–æ—Ä–∏—Ç–º –ö–æ—Å–∞—Ä–∞—é)"""
        if not self.directed:
            raise ValueError("SCC —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–æ–≤")
        
        # –ü–µ—Ä–≤—ã–π DFS –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        visited = set()
        finish_order = []
        
        def dfs1(vertex):
            visited.add(vertex)
            for neighbor in self.edges[vertex]:
                if neighbor not in visited:
                    dfs1(neighbor)
            finish_order.append(vertex)
        
        for vertex in self.vertices:
            if vertex not in visited:
                dfs1(vertex)
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ
        transposed = Graph(directed=True)
        for vertex in self.vertices:
            transposed.add_vertex(vertex)
        
        for u in self.vertices:
            for v in self.edges[u]:
                transposed.add_edge(v, u)
        
        # –í—Ç–æ—Ä–æ–π DFS –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        visited = set()
        scc_list = []
        
        def dfs2(vertex, component):
            visited.add(vertex)
            component.append(vertex)
            for neighbor in transposed.edges[vertex]:
                if neighbor not in visited:
                    dfs2(neighbor, component)
        
        for vertex in reversed(finish_order):
            if vertex not in visited:
                component = []
                dfs2(vertex, component)
                scc_list.append(component)
        
        return scc_list
```

---

## –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã

### –ú–µ—Ç–æ–¥—ã —Ä–µ—à–µ–Ω–∏—è —É—Ä–∞–≤–Ω–µ–Ω–∏–π
```python
class NumericalMethods:
    """–ß–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã"""
    
    @staticmethod
    def bisection_method(f, a, b, tol=1e-6, max_iter=1000):
        """–ú–µ—Ç–æ–¥ –±–∏—Å–µ–∫—Ü–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ—Ä–Ω—è"""
        if f(a) * f(b) >= 0:
            raise ValueError("f(a) –∏ f(b) –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞–∫–∏")
        
        for _ in range(max_iter):
            c = (a + b) / 2
            
            if abs(f(c)) < tol or abs(b - a) < tol:
                return c
            
            if f(a) * f(c) < 0:
                b = c
            else:
                a = c
        
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ—Ä–µ–Ω—å –∑–∞ –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π")
    
    @staticmethod
    def newton_method(f, df, x0, tol=1e-6, max_iter=1000):
        """–ú–µ—Ç–æ–¥ –ù—å—é—Ç–æ–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ—Ä–Ω—è"""
        x = x0
        
        for _ in range(max_iter):
            fx = f(x)
            
            if abs(fx) < tol:
                return x
            
            dfx = df(x)
            if abs(dfx) < 1e-12:
                raise ValueError("–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é")
            
            x = x - fx / dfx
        
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ—Ä–µ–Ω—å –∑–∞ –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π")
    
    @staticmethod
    def trapezoidal_rule(f, a, b, n=1000):
        """–ú–µ—Ç–æ–¥ —Ç—Ä–∞–ø–µ—Ü–∏–π –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è"""
        h = (b - a) / n
        result = 0.5 * (f(a) + f(b))
        
        for i in range(1, n):
            x = a + i * h
            result += f(x)
        
        return result * h
    
    @staticmethod
    def simpson_rule(f, a, b, n=1000):
        """–ú–µ—Ç–æ–¥ –°–∏–º–ø—Å–æ–Ω–∞ –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if n % 2 == 1:
            n += 1  # n –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —á–µ—Ç–Ω—ã–º
        
        h = (b - a) / n
        result = f(a) + f(b)
        
        for i in range(1, n):
            x = a + i * h
            if i % 2 == 0:
                result += 2 * f(x)
            else:
                result += 4 * f(x)
        
        return result * h / 3
    
    @staticmethod
    def runge_kutta_4(f, y0, x0, x_end, h=0.1):
        """–ú–µ—Ç–æ–¥ –†—É–Ω–≥–µ-–ö—É—Ç—Ç–∞ 4-–≥–æ –ø–æ—Ä—è–¥–∫–∞ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –û–î–£"""
        x = x0
        y = y0
        x_values = [x]
        y_values = [y]
        
        while x < x_end:
            k1 = h * f(x, y)
            k2 = h * f(x + h/2, y + k1/2)
            k3 = h * f(x + h/2, y + k2/2)
            k4 = h * f(x + h, y + k3)
            
            y += (k1 + 2*k2 + 2*k3 + k4) / 6
            x += h
            
            x_values.append(x)
            y_values.append(y)
        
        return x_values, y_values
    
    @staticmethod
    def gradient_descent(f, grad_f, x0, learning_rate=0.01, tol=1e-6, max_iter=10000):
        """–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏"""
        x = np.array(x0)
        
        for i in range(max_iter):
            grad = grad_f(x)
            
            if np.linalg.norm(grad) < tol:
                return x, i
            
            x = x - learning_rate * grad
        
        return x, max_iter
    
    @staticmethod
    def monte_carlo_integration(f, a, b, n=1000000):
        """–ú–µ—Ç–æ–¥ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –¥–ª—è —á–∏—Å–ª–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ —Ç–æ—á–∫–∏
        x_random = np.random.uniform(a, b, n)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
        f_values = np.array([f(x) for x in x_random])
        
        # –û—Ü–µ–Ω–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞–ª–∞
        integral = (b - a) * np.mean(f_values)
        
        return integral

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
def demonstrate_numerical_methods():
    # –ü–æ–∏—Å–∫ –∫–æ—Ä–Ω—è x^2 - 2 = 0
    f = lambda x: x**2 - 2
    df = lambda x: 2*x
    
    # –ú–µ—Ç–æ–¥ –±–∏—Å–µ–∫—Ü–∏–∏
    root_bisection = NumericalMethods.bisection_method(f, 0, 2)
    print(f"–ö–æ—Ä–µ–Ω—å (–±–∏—Å–µ–∫—Ü–∏—è): {root_bisection}")
    
    # –ú–µ—Ç–æ–¥ –ù—å—é—Ç–æ–Ω–∞
    root_newton = NumericalMethods.newton_method(f, df, 1.0)
    print(f"–ö–æ—Ä–µ–Ω—å (–ù—å—é—Ç–æ–Ω): {root_newton}")
    
    # –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ x^2 –æ—Ç 0 –¥–æ 1
    g = lambda x: x**2
    
    integral_trap = NumericalMethods.trapezoidal_rule(g, 0, 1)
    integral_simpson = NumericalMethods.simpson_rule(g, 0, 1)
    integral_mc = NumericalMethods.monte_carlo_integration(g, 0, 1)
    
    print(f"–ò–Ω—Ç–µ–≥—Ä–∞–ª (—Ç—Ä–∞–ø–µ—Ü–∏–∏): {integral_trap}")
    print(f"–ò–Ω—Ç–µ–≥—Ä–∞–ª (–°–∏–º–ø—Å–æ–Ω): {integral_simpson}")
    print(f"–ò–Ω—Ç–µ–≥—Ä–∞–ª (–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ): {integral_mc}")
    print(f"–¢–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {1/3}")
```

---

## –¢–µ–æ—Ä–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

### –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
```python
class InformationTheory:
    """–¢–µ–æ—Ä–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    
    @staticmethod
    def entropy(probabilities):
        """–≠–Ω—Ç—Ä–æ–ø–∏—è –®–µ–Ω–Ω–æ–Ω–∞"""
        return -sum(p * np.log2(p) for p in probabilities if p > 0)
    
    @staticmethod
    def cross_entropy(p, q):
        """–ü–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è"""
        return -sum(p[i] * np.log2(q[i]) for i in range(len(p)) if p[i] > 0 and q[i] > 0)
    
    @staticmethod
    def kl_divergence(p, q):
        """–î–∏–≤–µ—Ä–≥–µ–Ω—Ü–∏—è –ö—É–ª—å–±–∞–∫–∞-–õ–µ–π–±–ª–µ—Ä–∞"""
        return sum(p[i] * np.log2(p[i] / q[i]) for i in range(len(p)) if p[i] > 0 and q[i] > 0)
    
    @staticmethod
    def mutual_information(joint_prob, marginal_x, marginal_y):
        """–í–∑–∞–∏–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"""
        mi = 0
        for i in range(len(marginal_x)):
            for j in range(len(marginal_y)):
                if joint_prob[i][j] > 0:
                    mi += joint_prob[i][j] * np.log2(joint_prob[i][j] / (marginal_x[i] * marginal_y[j]))
        return mi
    
    @staticmethod
    def huffman_coding(frequencies):
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –•–∞—Ñ—Ñ–º–∞–Ω–∞"""
        import heapq
        
        # –°–æ–∑–¥–∞–µ–º —É–∑–ª—ã –¥–µ—Ä–µ–≤–∞
        heap = [[freq, i, char] for i, (char, freq) in enumerate(frequencies.items())]
        heapq.heapify(heap)
        
        # –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ
        while len(heap) > 1:
            lo = heapq.heappop(heap)
            hi = heapq.heappop(heap)
            
            for pair in lo[2:]:
                pair[1] = '0' + pair[1]
            for pair in hi[2:]:
                pair[1] = '1' + pair[1]
            
            heapq.heappush(heap, [lo[0] + hi[0]] + lo[2:] + hi[2:])
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥—ã
        codes = {}
        for pair in heap[0][2:]:
            codes[pair[0]] = pair[1]
        
        return codes
    
    @staticmethod
    def compression_ratio(original_size, compressed_size):
        """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è"""
        return original_size / compressed_size
    
    @staticmethod
    def channel_capacity(snr_db):
        """–ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–∞ (—Ñ–æ—Ä–º—É–ª–∞ –®–µ–Ω–Ω–æ–Ω–∞)"""
        snr_linear = 10 ** (snr_db / 10)
        return np.log2(1 + snr_linear)

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–µ–æ—Ä–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
def demonstrate_information_theory():
    # –≠–Ω—Ç—Ä–æ–ø–∏—è
    prob_dist = [0.5, 0.25, 0.125, 0.125]
    entropy = InformationTheory.entropy(prob_dist)
    print(f"–≠–Ω—Ç—Ä–æ–ø–∏—è: {entropy:.3f} –±–∏—Ç")
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –•–∞—Ñ—Ñ–º–∞–Ω–∞
    frequencies = {'A': 0.5, 'B': 0.25, 'C': 0.125, 'D': 0.125}
    codes = InformationTheory.huffman_coding(frequencies)
    print(f"–ö–æ–¥—ã –•–∞—Ñ—Ñ–º–∞–Ω–∞: {codes}")
    
    # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–¥–∞
    avg_length = sum(len(codes[char]) * freq for char, freq in frequencies.items())
    print(f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –∫–æ–¥–∞: {avg_length:.3f}")
    print(f"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {entropy/avg_length:.3f}")
```

## –°–≤—è–∑—å —Å –¥—Ä—É–≥–∏–º–∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏

- **[–ê–ª–≥–æ—Ä–∏—Ç–º—ã](./algorithms.md)** - –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
- **[Machine Learning](./machine-learning-ai.md)** - –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã ML
- **[–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞](./statistics.md)** - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã
- **[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è](./optimization.md)** - –ú–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

---

*–°–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑–¥–µ–ª: [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è ‚Üí](./real-world-applications.md)* 