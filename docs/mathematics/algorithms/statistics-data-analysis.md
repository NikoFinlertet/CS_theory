# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö üìä

> **–ù–∞–≤–∏–≥–∞—Ü–∏—è**: [[number-theory-cryptography|‚Üê –¢–µ–æ—Ä–∏—è —á–∏—Å–µ–ª]] | [[mathematics-algorithms|–ì–ª–∞–≤–Ω–∞—è]] | [[combinatorics-generation|–ö–æ–º–±–∏–Ω–∞—Ç–æ—Ä–∏–∫–∞ ‚Üí]]

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
1. [–î–µ—Å–∫—Ä–∏–ø—Ç–∏–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞](#üìä-–¥–µ—Å–∫—Ä–∏–ø—Ç–∏–≤–Ω–∞—è-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
2. [–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã](#üß™-—Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ-—Ç–µ—Å—Ç—ã)
3. [–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è](#üìà-–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è-–∏-—Ä–µ–≥—Ä–µ—Å—Å–∏—è)
4. [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è](#üöÄ-–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ-–ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è)

---

## üìä –î–µ—Å–∫—Ä–∏–ø—Ç–∏–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Å–Ω–æ–≤–∞:** –ú–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏, –º–µ—Ä—ã —Ä–∞–∑–±—Ä–æ—Å–∞, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è

```python
import math
import numpy as np
from collections import Counter

class DescriptiveStatistics:
    """–î–µ—Å–∫—Ä–∏–ø—Ç–∏–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    
    @staticmethod
    def mean(data):
        """–°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ"""
        return sum(data) / len(data)
    
    @staticmethod
    def median(data):
        """–ú–µ–¥–∏–∞–Ω–∞ - –∑–Ω–∞—á–µ–Ω–∏–µ, —Ä–∞–∑–¥–µ–ª—è—é—â–µ–µ –≤—ã–±–æ—Ä–∫—É –ø–æ–ø–æ–ª–∞–º"""
        sorted_data = sorted(data)
        n = len(sorted_data)
        
        if n % 2 == 0:
            return (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2
        else:
            return sorted_data[n//2]
    
    @staticmethod
    def mode(data):
        """–ú–æ–¥–∞ - –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–µ–µ—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ"""
        counter = Counter(data)
        max_count = max(counter.values())
        return [value for value, count in counter.items() if count == max_count]
    
    @staticmethod
    def variance(data, ddof=0):
        """
        –î–∏—Å–ø–µ—Ä—Å–∏—è
        ddof=0 –¥–ª—è –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏
        ddof=1 –¥–ª—è –≤—ã–±–æ—Ä–∫–∏
        """
        mean_val = DescriptiveStatistics.mean(data)
        squared_deviations = [(x - mean_val)**2 for x in data]
        return sum(squared_deviations) / (len(data) - ddof)
    
    @staticmethod
    def standard_deviation(data, ddof=0):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"""
        return math.sqrt(DescriptiveStatistics.variance(data, ddof))
    
    @staticmethod
    def quantile(data, q):
        """–ö–≤–∞–Ω—Ç–∏–ª—å —É—Ä–æ–≤–Ω—è q (0 ‚â§ q ‚â§ 1)"""
        sorted_data = sorted(data)
        n = len(sorted_data)
        index = q * (n - 1)
        
        if index.is_integer():
            return sorted_data[int(index)]
        else:
            lower = sorted_data[int(index)]
            upper = sorted_data[int(index) + 1]
            return lower + (index - int(index)) * (upper - lower)
    
    @staticmethod
    def five_number_summary(data):
        """–ü—è—Ç–∏—á–∏—Å–ª–æ–≤–æ–µ —Ä–µ–∑—é–º–µ: –º–∏–Ω, Q1, –º–µ–¥–∏–∞–Ω–∞, Q3, –º–∞–∫—Å"""
        return {
            'min': min(data),
            'Q1': DescriptiveStatistics.quantile(data, 0.25),
            'median': DescriptiveStatistics.median(data),
            'Q3': DescriptiveStatistics.quantile(data, 0.75),
            'max': max(data)
        }
    
    @staticmethod
    def correlation_coefficient(x, y):
        """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞"""
        n = len(x)
        if n != len(y):
            raise ValueError("–í–µ–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã")
        
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(x[i]**2 for i in range(n))
        sum_y2 = sum(y[i]**2 for i in range(n))
        
        numerator = n * sum_xy - sum_x * sum_y
        denominator = math.sqrt((n * sum_x2 - sum_x**2) * (n * sum_y2 - sum_y**2))
        
        if denominator == 0:
            return 0
        
        return numerator / denominator

class OnlineStatistics:
    """–û–Ω–ª–∞–π–Ω-–∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.count = 0
        self.mean = 0
        self.m2 = 0  # –î–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        self.min_val = float('inf')
        self.max_val = float('-inf')
    
    def update(self, value):
        """
        –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
        –ê–ª–≥–æ—Ä–∏—Ç–º –£—ç–ª—Ñ–æ—Ä–¥–∞ –¥–ª—è –æ–Ω–ª–∞–π–Ω-–≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        """
        self.count += 1
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∏–Ω–∏–º—É–º–∞ –∏ –º–∞–∫—Å–∏–º—É–º–∞
        self.min_val = min(self.min_val, value)
        self.max_val = max(self.max_val, value)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
        delta = value - self.mean
        self.mean += delta / self.count
        delta2 = value - self.mean
        self.m2 += delta * delta2
    
    def get_mean(self):
        """–¢–µ–∫—É—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ"""
        return self.mean
    
    def get_variance(self, ddof=0):
        """–¢–µ–∫—É—â–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è"""
        if self.count < 2:
            return 0
        return self.m2 / (self.count - ddof)
    
    def get_std(self, ddof=0):
        """–¢–µ–∫—É—â–µ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"""
        return math.sqrt(self.get_variance(ddof))
    
    def get_range(self):
        """–†–∞–∑–º–∞—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return self.max_val - self.min_val
```

---

## üß™ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã

```python
class StatisticalTests:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑"""
    
    @staticmethod
    def t_test_one_sample(data, population_mean, alpha=0.05):
        """
        –û–¥–Ω–æ–≤—ã–±–æ—Ä–æ—á–Ω—ã–π t-—Ç–µ—Å—Ç
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç H0: Œº = population_mean –ø—Ä–æ—Ç–∏–≤ H1: Œº ‚â† population_mean
        """
        n = len(data)
        sample_mean = DescriptiveStatistics.mean(data)
        sample_std = DescriptiveStatistics.standard_deviation(data, ddof=1)
        
        # t-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        t_statistic = (sample_mean - population_mean) / (sample_std / math.sqrt(n))
        
        # –°—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±–æ–¥—ã
        df = n - 1
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –≤—ã–±–æ—Ä–æ–∫)
        t_critical = 1.96 if n > 30 else 2.0  # –£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
        
        p_value = 2 * (1 - StatisticalTests._t_cdf(abs(t_statistic), df))
        
        return {
            't_statistic': t_statistic,
            'p_value': p_value,
            'critical_value': t_critical,
            'reject_null': abs(t_statistic) > t_critical or p_value < alpha,
            'confidence_interval': StatisticalTests._confidence_interval(
                sample_mean, sample_std, n, alpha
            )
        }
    
    @staticmethod
    def _t_cdf(t, df):
        """–ü—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–∞—è CDF –¥–ª—è t-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        if df > 30:
            # –î–ª—è –±–æ–ª—å—à–∏—Ö df t-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–ª–∏–∑–∫–æ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É
            return StatisticalTests._normal_cdf(t)
        else:
            # –û—á–µ–Ω—å –≥—Ä—É–±–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
            return 0.5 + 0.5 * math.tanh(t / 2)
    
    @staticmethod
    def _normal_cdf(x):
        """–ü—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–∞—è CDF –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
        return 0.5 * (1 + math.erf(x / math.sqrt(2)))
    
    @staticmethod
    def _confidence_interval(mean, std, n, alpha):
        """–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ"""
        margin_error = 1.96 * std / math.sqrt(n)  # –ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –≤—ã–±–æ—Ä–æ–∫
        return (mean - margin_error, mean + margin_error)
    
    @staticmethod
    def chi_square_test(observed, expected):
        """
        –¢–µ—Å—Ç —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≥–ª–∞—Å–∏—è
        H0: –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ —á–∞—Å—Ç–æ—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–µ–º—ã–º
        """
        if len(observed) != len(expected):
            raise ValueError("–í–µ–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã")
        
        chi_square = sum((obs - exp)**2 / exp for obs, exp in zip(observed, expected))
        df = len(observed) - 1
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ–µ)
        critical_value = 3.84 if df == 1 else 5.99 if df == 2 else 7.81
        
        return {
            'chi_square': chi_square,
            'degrees_of_freedom': df,
            'critical_value': critical_value,
            'reject_null': chi_square > critical_value
        }
    
    @staticmethod
    def ab_test_analysis(control_group, treatment_group, alpha=0.05):
        """
        A/B —Ç–µ—Å—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–≤—É—Ö –≥—Ä—É–ø–ø
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–≤—É—Ö–≤—ã–±–æ—Ä–æ—á–Ω—ã–π t-—Ç–µ—Å—Ç
        """
        n1, n2 = len(control_group), len(treatment_group)
        mean1 = DescriptiveStatistics.mean(control_group)
        mean2 = DescriptiveStatistics.mean(treatment_group)
        var1 = DescriptiveStatistics.variance(control_group, ddof=1)
        var2 = DescriptiveStatistics.variance(treatment_group, ddof=1)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
        pooled_var = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Ä–∞–∑–Ω–æ—Å—Ç–∏ —Å—Ä–µ–¥–Ω–∏—Ö
        se = math.sqrt(pooled_var * (1/n1 + 1/n2))
        
        # t-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        t_statistic = (mean2 - mean1) / se
        
        # –°—Ç–µ–ø–µ–Ω–∏ —Å–≤–æ–±–æ–¥—ã
        df = n1 + n2 - 2
        
        # –†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d)
        cohens_d = (mean2 - mean1) / math.sqrt(pooled_var)
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        t_critical = 1.96 if df > 30 else 2.0
        
        return {
            'control_mean': mean1,
            'treatment_mean': mean2,
            'difference': mean2 - mean1,
            'relative_improvement': (mean2 - mean1) / mean1 * 100,
            't_statistic': t_statistic,
            'cohens_d': cohens_d,
            'critical_value': t_critical,
            'statistically_significant': abs(t_statistic) > t_critical,
            'effect_size': 'small' if abs(cohens_d) < 0.5 else 'medium' if abs(cohens_d) < 0.8 else 'large'
        }

class ABTestFramework:
    """–§—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è A/B —Ç–µ—Å—Ç–æ–≤"""
    
    def __init__(self, name, hypothesis):
        self.name = name
        self.hypothesis = hypothesis
        self.control_data = []
        self.treatment_data = []
        self.start_time = None
        self.end_time = None
    
    def add_observation(self, group, value):
        """–î–æ–±–∞–≤–∏—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –≤ –≥—Ä—É–ø–ø—É"""
        if group == 'control':
            self.control_data.append(value)
        elif group == 'treatment':
            self.treatment_data.append(value)
        else:
            raise ValueError("–ì—Ä—É–ø–ø–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 'control' –∏–ª–∏ 'treatment'")
    
    def calculate_sample_size(self, effect_size, power=0.8, alpha=0.05):
        """
        –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è A/B —Ç–µ—Å—Ç–∞
        –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ –¥–ª—è —Ä–∞–≤–Ω—ã—Ö –≥—Ä—É–ø–ø
        """
        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        z_alpha = 1.96  # –¥–ª—è alpha = 0.05
        z_beta = 0.84   # –¥–ª—è power = 0.8
        
        n = 2 * ((z_alpha + z_beta) / effect_size) ** 2
        return math.ceil(n)
    
    def analyze(self):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ A/B —Ç–µ—Å—Ç–∞"""
        if len(self.control_data) == 0 or len(self.treatment_data) == 0:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        return StatisticalTests.ab_test_analysis(self.control_data, self.treatment_data)
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ A/B —Ç–µ—Å—Ç—É"""
        results = self.analyze()
        
        report = f"""
        A/B Test Report: {self.name}
        ================================
        
        Hypothesis: {self.hypothesis}
        
        Sample Sizes:
        - Control: {len(self.control_data)}
        - Treatment: {len(self.treatment_data)}
        
        Results:
        - Control Mean: {results['control_mean']:.4f}
        - Treatment Mean: {results['treatment_mean']:.4f}
        - Difference: {results['difference']:.4f}
        - Relative Improvement: {results['relative_improvement']:.2f}%
        
        Statistical Significance:
        - t-statistic: {results['t_statistic']:.4f}
        - Statistically Significant: {results['statistically_significant']}
        
        Effect Size:
        - Cohen's d: {results['cohens_d']:.4f}
        - Effect Size: {results['effect_size']}
        
        Recommendation:
        {'Implement treatment' if results['statistically_significant'] and results['difference'] > 0 
         else 'Continue with control' if results['statistically_significant'] 
         else 'Inconclusive - collect more data'}
        """
        
        return report
```

---

## üìà –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è

```python
class RegressionAnalysis:
    """–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
    
    @staticmethod
    def simple_linear_regression(x, y):
        """
        –ü—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è: y = a + bx
        –ú–µ—Ç–æ–¥ –Ω–∞–∏–º–µ–Ω—å—à–∏—Ö –∫–≤–∞–¥—Ä–∞—Ç–æ–≤
        """
        n = len(x)
        if n != len(y):
            raise ValueError("–í–µ–∫—Ç–æ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω—ã")
        
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(x[i]**2 for i in range(n))
        
        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        b = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x**2)
        a = (sum_y - b * sum_x) / n
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        y_pred = [a + b * xi for xi in x]
        
        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ R¬≤
        y_mean = sum(y) / n
        ss_tot = sum((yi - y_mean)**2 for yi in y)
        ss_res = sum((y[i] - y_pred[i])**2 for i in range(n))
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 1
        
        return {
            'intercept': a,
            'slope': b,
            'r_squared': r_squared,
            'predictions': y_pred,
            'equation': f'y = {a:.4f} + {b:.4f}x'
        }
    
    @staticmethod
    def polynomial_regression(x, y, degree=2):
        """–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è"""
        n = len(x)
        
        # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –í–∞–Ω–¥–µ—Ä–º–æ–Ω–¥–∞
        X = [[xi**j for j in range(degree + 1)] for xi in x]
        
        # –†–µ—à–∞–µ–º —Å–∏—Å—Ç–µ–º—É –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏–π X^T * X * beta = X^T * y
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (degree=2)
        if degree == 2:
            sum_x = sum(x)
            sum_x2 = sum(xi**2 for xi in x)
            sum_x3 = sum(xi**3 for xi in x)
            sum_x4 = sum(xi**4 for xi in x)
            sum_y = sum(y)
            sum_xy = sum(x[i] * y[i] for i in range(n))
            sum_x2y = sum(x[i]**2 * y[i] for i in range(n))
            
            # –†–µ—à–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã 3x3 (—É–ø—Ä–æ—â–µ–Ω–Ω–æ–µ)
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–ª–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ—à–µ–Ω–∏—è –°–õ–ê–£
            # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é
            return RegressionAnalysis.simple_linear_regression(x, y)
        else:
            return RegressionAnalysis.simple_linear_regression(x, y)

class TimeSeriesAnalysis:
    """–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    
    @staticmethod
    def moving_average(data, window_size):
        """–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ"""
        if window_size > len(data):
            raise ValueError("–†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")
        
        result = []
        for i in range(len(data) - window_size + 1):
            window = data[i:i + window_size]
            result.append(sum(window) / window_size)
        
        return result
    
    @staticmethod
    def exponential_smoothing(data, alpha=0.3):
        """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ"""
        if not (0 < alpha <= 1):
            raise ValueError("–ê–ª—å—Ñ–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ (0, 1]")
        
        smoothed = [data[0]]  # –ü–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–µ–∏–∑–º–µ–Ω–Ω—ã–º
        
        for i in range(1, len(data)):
            smoothed_value = alpha * data[i] + (1 - alpha) * smoothed[i - 1]
            smoothed.append(smoothed_value)
        
        return smoothed
    
    @staticmethod
    def detect_trend(data):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –º–µ—Ç–æ–¥–æ–º –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏"""
        x = list(range(len(data)))
        regression_result = RegressionAnalysis.simple_linear_regression(x, data)
        
        slope = regression_result['slope']
        
        if slope > 0.1:
            return 'increasing'
        elif slope < -0.1:
            return 'decreasing'
        else:
            return 'stable'
    
    @staticmethod
    def seasonal_decomposition(data, period):
        """–ü—Ä–æ—Å—Ç–æ–µ —Å–µ–∑–æ–Ω–Ω–æ–µ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ"""
        if len(data) < period * 2:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ–≥–æ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏—è")
        
        # –¢—Ä–µ–Ω–¥ (—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)
        trend = TimeSeriesAnalysis.moving_average(data, period)
        
        # –î–æ–ø–æ–ª–Ω—è–µ–º —Ç—Ä–µ–Ω–¥ –¥–æ –ø–æ–ª–Ω–æ–π –¥–ª–∏–Ω—ã
        trend_full = [None] * (period // 2) + trend + [None] * (period // 2)
        
        # –°–µ–∑–æ–Ω–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        seasonal = []
        for i in range(len(data)):
            if trend_full[i] is not None:
                seasonal.append(data[i] - trend_full[i])
            else:
                seasonal.append(0)
        
        # –û—Å—Ç–∞—Ç–∫–∏
        residual = []
        for i in range(len(data)):
            if trend_full[i] is not None:
                residual.append(data[i] - trend_full[i] - seasonal[i])
            else:
                residual.append(0)
        
        return {
            'original': data,
            'trend': trend_full,
            'seasonal': seasonal,
            'residual': residual
        }
```

---

## üöÄ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

```python
class WebAnalyticsStatistics:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –≤–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    
    def __init__(self):
        self.page_views = []
        self.conversion_rates = []
        self.session_durations = []
    
    def add_session_data(self, page_views, converted, duration):
        """–î–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏"""
        self.page_views.append(page_views)
        self.conversion_rates.append(1 if converted else 0)
        self.session_durations.append(duration)
    
    def calculate_metrics(self):
        """–†–∞—Å—á–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        total_sessions = len(self.page_views)
        
        if total_sessions == 0:
            return {}
        
        metrics = {
            'total_sessions': total_sessions,
            'avg_page_views': DescriptiveStatistics.mean(self.page_views),
            'conversion_rate': DescriptiveStatistics.mean(self.conversion_rates),
            'avg_session_duration': DescriptiveStatistics.mean(self.session_durations),
            'bounce_rate': sum(1 for pv in self.page_views if pv == 1) / total_sessions,
            'page_views_stats': DescriptiveStatistics.five_number_summary(self.page_views)
        }
        
        return metrics
    
    def compare_periods(self, other_period):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ø–µ—Ä–∏–æ–¥–æ–≤"""
        current_metrics = self.calculate_metrics()
        other_metrics = other_period.calculate_metrics()
        
        if not current_metrics or not other_metrics:
            return None
        
        comparison = {}
        for metric in ['conversion_rate', 'avg_page_views', 'avg_session_duration']:
            if metric in current_metrics and metric in other_metrics:
                current_val = current_metrics[metric]
                other_val = other_metrics[metric]
                
                if other_val != 0:
                    change_percent = (current_val - other_val) / other_val * 100
                    comparison[metric] = {
                        'current': current_val,
                        'previous': other_val,
                        'change_percent': change_percent,
                        'improvement': change_percent > 0
                    }
        
        return comparison

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def demo_statistics():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤"""
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    import random
    random.seed(42)
    
    # –î–∞–Ω–Ω—ã–µ –¥–ª—è A/B —Ç–µ—Å—Ç–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏
    control_conversions = [random.random() < 0.12 for _ in range(1000)]  # 12% –±–∞–∑–æ–≤–∞—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è
    treatment_conversions = [random.random() < 0.15 for _ in range(1000)]  # 15% –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ A/B —Ç–µ—Å—Ç–∞
    ab_test = ABTestFramework(
        "Landing Page Optimization",
        "–ù–æ–≤—ã–π –¥–∏–∑–∞–π–Ω –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏—é"
    )
    
    for conversion in control_conversions:
        ab_test.add_observation('control', conversion)
    
    for conversion in treatment_conversions:
        ab_test.add_observation('treatment', conversion)
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(ab_test.generate_report())
    
    # –í–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞
    analytics = WebAnalyticsStatistics()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–π
    for _ in range(1000):
        page_views = random.randint(1, 10)
        converted = random.random() < 0.1
        duration = random.randint(30, 600)  # —Å–µ–∫—É–Ω–¥—ã
        analytics.add_session_data(page_views, converted, duration)
    
    metrics = analytics.calculate_metrics()
    print(f"\n–í–µ–±-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞:")
    print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Å—Å–∏–π: {metrics['total_sessions']}")
    print(f"–°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü: {metrics['avg_page_views']:.2f}")
    print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ–Ω–≤–µ—Ä—Å–∏–∏: {metrics['conversion_rate']:.2%}")
    print(f"–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–∏: {metrics['avg_session_duration']:.0f} —Å–µ–∫")
    print(f"–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å –æ—Ç–∫–∞–∑–æ–≤: {metrics['bounce_rate']:.2%}")
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã:**

- ‚úÖ **A/B —Ç–µ—Å—Ç—ã**: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞, –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
- ‚úÖ **–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –º–µ—Ç—Ä–∏–∫
- ‚úÖ **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑**: –í—ã—è–≤–ª–µ–Ω–∏–µ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
- ‚úÖ **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã**: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã, –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ

---

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã

- [[probability-randomized-algorithms|–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã]] - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
- [[calculus-optimization|–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑]] - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤ ML
- [[linear-algebra-computation|–õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞]] - –º–Ω–æ–≥–æ–º–µ—Ä–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- [[../probability-statistics/practical-applications|–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏]]

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **–ö–Ω–∏–≥–∏**: "The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman
- **–ö—É—Ä—Å—ã**: Stanford CS109, MIT 18.05
- **–ü—Ä–∞–∫—Ç–∏–∫–∞**: Kaggle competitions, A/B testing platforms 