# –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ üìà

> [[probability-theory|‚Üê –û—Å–Ω–æ–≤—ã —Ç–µ–æ—Ä–∏–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π]] | [[README|–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ]] | [[statistical-tests|–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã ‚Üí]]

## üéØ –ß—Ç–æ –∏–∑—É—á–∏–º

- **–ú–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏** - —Å—Ä–µ–¥–Ω–µ–µ, –º–µ–¥–∏–∞–Ω–∞, –º–æ–¥–∞
- **–ú–µ—Ä—ã —Ä–∞–∑–±—Ä–æ—Å–∞** - –¥–∏—Å–ø–µ—Ä—Å–∏—è, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, –∫–≤–∞—Ä—Ç–∏–ª–∏
- **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è** - —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏

---

## 1. –ú–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏

```python
import statistics
import math

class StatisticalAnalyzer:
    def __init__(self, data):
        self.data = data
    
    def mean(self):
        """–°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ"""
        return sum(self.data) / len(self.data)
    
    def median(self):
        """–ú–µ–¥–∏–∞–Ω–∞"""
        sorted_data = sorted(self.data)
        n = len(sorted_data)
        if n % 2 == 0:
            return (sorted_data[n//2 - 1] + sorted_data[n//2]) / 2
        else:
            return sorted_data[n//2]
    
    def mode(self):
        """–ú–æ–¥–∞"""
        frequency = {}
        for value in self.data:
            frequency[value] = frequency.get(value, 0) + 1
        max_freq = max(frequency.values())
        return [value for value, freq in frequency.items() if freq == max_freq]
    
    def variance(self):
        """–î–∏—Å–ø–µ—Ä—Å–∏—è"""
        mean = self.mean()
        return sum((x - mean) ** 2 for x in self.data) / len(self.data)
    
    def standard_deviation(self):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"""
        return math.sqrt(self.variance())
    
    def quartiles(self):
        """–ö–≤–∞—Ä—Ç–∏–ª–∏"""
        sorted_data = sorted(self.data)
        n = len(sorted_data)
        
        q1_index = n // 4
        q2_index = n // 2
        q3_index = 3 * n // 4
        
        return {
            'Q1': sorted_data[q1_index],
            'Q2': sorted_data[q2_index],
            'Q3': sorted_data[q3_index]
        }
    
    def outliers(self):
        """–í—ã–±—Ä–æ—Å—ã –ø–æ –ø—Ä–∞–≤–∏–ª—É IQR"""
        quartiles = self.quartiles()
        iqr = quartiles['Q3'] - quartiles['Q1']
        lower_bound = quartiles['Q1'] - 1.5 * iqr
        upper_bound = quartiles['Q3'] + 1.5 * iqr
        
        return [x for x in self.data if x < lower_bound or x > upper_bound]

# –ü—Ä–∏–º–µ—Ä: –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
query_times = [15, 23, 18, 45, 12, 28, 19, 34, 16, 25, 180, 21, 17, 29, 22]
analyzer = StatisticalAnalyzer(query_times)

print("–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î:")
print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {analyzer.mean():.2f} –º—Å")
print(f"–ú–µ–¥–∏–∞–Ω–∞: {analyzer.median():.2f} –º—Å")
print(f"–ú–æ–¥–∞: {analyzer.mode()}")
print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {analyzer.standard_deviation():.2f} –º—Å")
print(f"–ö–≤–∞—Ä—Ç–∏–ª–∏: {analyzer.quartiles()}")
print(f"–í—ã–±—Ä–æ—Å—ã: {analyzer.outliers()}")
```

### üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫—É—é –º–µ—Ä—É

| –ú–µ—Ä–∞ | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å | –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º |
|------|-------------------|------------------------|
| **–°—Ä–µ–¥–Ω–µ–µ** | –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ | –ù–∏–∑–∫–∞—è |
| **–ú–µ–¥–∏–∞–Ω–∞** | –ï—Å—Ç—å –≤—ã–±—Ä–æ—Å—ã | –í—ã—Å–æ–∫–∞—è |
| **–ú–æ–¥–∞** | –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ | –°—Ä–µ–¥–Ω—è—è |

---

## 2. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è

```python
class CorrelationAnalyzer:
    def __init__(self, x_data, y_data):
        self.x_data = x_data
        self.y_data = y_data
    
    def correlation_coefficient(self):
        """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞"""
        n = len(self.x_data)
        mean_x = sum(self.x_data) / n
        mean_y = sum(self.y_data) / n
        
        numerator = sum((x - mean_x) * (y - mean_y) for x, y in zip(self.x_data, self.y_data))
        denominator_x = sum((x - mean_x) ** 2 for x in self.x_data)
        denominator_y = sum((y - mean_y) ** 2 for y in self.y_data)
        
        return numerator / math.sqrt(denominator_x * denominator_y)
    
    def linear_regression(self):
        """–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è y = ax + b"""
        n = len(self.x_data)
        mean_x = sum(self.x_data) / n
        mean_y = sum(self.y_data) / n
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤
        numerator = sum((x - mean_x) * (y - mean_y) for x, y in zip(self.x_data, self.y_data))
        denominator = sum((x - mean_x) ** 2 for x in self.x_data)
        
        a = numerator / denominator
        b = mean_y - a * mean_x
        
        return a, b
    
    def r_squared(self):
        """–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏"""
        return self.correlation_coefficient() ** 2

# –ü—Ä–∏–º–µ—Ä: —Å–≤—è–∑—å –º–µ–∂–¥—É —Ä–∞–∑–º–µ—Ä–æ–º –∫–æ–º–∞–Ω–¥—ã –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
team_sizes = [2, 3, 4, 5, 6, 7, 8, 9, 10, 12]
features_per_sprint = [8, 12, 15, 18, 20, 19, 17, 15, 12, 10]

analyzer = CorrelationAnalyzer(team_sizes, features_per_sprint)
correlation = analyzer.correlation_coefficient()
a, b = analyzer.linear_regression()
r_squared = analyzer.r_squared()

print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–º–∞–Ω–¥—ã –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {correlation:.3f}")
print(f"–£—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏: y = {a:.2f}x + {b:.2f}")
print(f"R¬≤: {r_squared:.3f}")

# –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
def predict_performance(team_size):
    return a * team_size + b

print(f"–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–æ–º–∞–Ω–¥—ã –∏–∑ 11 —á–µ–ª–æ–≤–µ–∫: {predict_performance(11):.1f} —Ñ–∏—á –∑–∞ —Å–ø—Ä–∏–Ω—Ç")
```

### üìä –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏

| –ó–Ω–∞—á–µ–Ω–∏–µ r | –°–∏–ª–∞ —Å–≤—è–∑–∏ | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è |
|------------|------------|---------------|
| **0.0 - 0.3** | –°–ª–∞–±–∞—è | –ü–æ—á—Ç–∏ –Ω–µ—Ç —Å–≤—è–∑–∏ |
| **0.3 - 0.7** | –°—Ä–µ–¥–Ω—è—è | –£–º–µ—Ä–µ–Ω–Ω–∞—è —Å–≤—è–∑—å |
| **0.7 - 1.0** | –°–∏–ª—å–Ω–∞—è | –°–∏–ª—å–Ω–∞—è —Å–≤—è–∑—å |

---

## 3. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

### –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
class PerformanceDashboard:
    def __init__(self):
        self.metrics = {
            'response_times': [],
            'memory_usage': [],
            'cpu_usage': [],
            'error_rates': []
        }
    
    def add_measurements(self, response_time, memory, cpu, errors):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π"""
        self.metrics['response_times'].append(response_time)
        self.metrics['memory_usage'].append(memory)
        self.metrics['cpu_usage'].append(cpu)
        self.metrics['error_rates'].append(errors)
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞"""
        report = {}
        
        for metric_name, values in self.metrics.items():
            if values:
                analyzer = StatisticalAnalyzer(values)
                report[metric_name] = {
                    'mean': analyzer.mean(),
                    'median': analyzer.median(),
                    'std_dev': analyzer.standard_deviation(),
                    'outliers_count': len(analyzer.outliers()),
                    'percentile_95': analyzer.quartiles()['Q3']  # –ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
                }
        
        return report
    
    def detect_correlations(self):
        """–ü–æ–∏—Å–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        correlations = {}
        metric_names = list(self.metrics.keys())
        
        for i in range(len(metric_names)):
            for j in range(i + 1, len(metric_names)):
                metric1 = metric_names[i]
                metric2 = metric_names[j]
                
                if self.metrics[metric1] and self.metrics[metric2]:
                    analyzer = CorrelationAnalyzer(
                        self.metrics[metric1], 
                        self.metrics[metric2]
                    )
                    corr = analyzer.correlation_coefficient()
                    correlations[f"{metric1}_vs_{metric2}"] = corr
        
        return correlations

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
dashboard = PerformanceDashboard()

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π
sample_data = [
    (120, 85, 45, 0.02),
    (135, 88, 52, 0.03),
    (110, 82, 38, 0.01),
    (180, 95, 65, 0.05),
    (125, 87, 48, 0.02)
]

for data in sample_data:
    dashboard.add_measurements(*data)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
report = dashboard.generate_report()
print("–û—Ç—á—ë—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
for metric, stats in report.items():
    print(f"\n{metric}:")
    print(f"  –°—Ä–µ–¥–Ω–µ–µ: {stats['mean']:.2f}")
    print(f"  –ú–µ–¥–∏–∞–Ω–∞: {stats['median']:.2f}")
    print(f"  –í—ã–±—Ä–æ—Å–æ–≤: {stats['outliers_count']}")

# –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
correlations = dashboard.detect_correlations()
print("\n–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏:")
for pair, corr in correlations.items():
    print(f"{pair}: {corr:.3f}")
```

---

## üìö –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã

- [[probability-theory|–û—Å–Ω–æ–≤—ã —Ç–µ–æ—Ä–∏–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π]] - —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
- [[statistical-tests|–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã]] - –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑
- [[time-series|–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã]] - –∞–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏

---

## üõ†Ô∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

### Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
```python
import statistics       # –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
import pandas as pd    # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
import numpy as np     # –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
import matplotlib.pyplot as plt  # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import seaborn as sns  # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
```

### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è

1. **–ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤** - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ API
2. **Correlation Analysis** - –Ω–∞–π–¥–∏—Ç–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
3. **Outlier Detection** - —Å–æ–∑–¥–∞–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

---

## üéØ –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

- **–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —Ç–µ–Ω–¥–µ–Ω—Ü–∏—è** - —Ç–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∞–Ω–Ω—ã—Ö
- **–†–∞–∑–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö** - –Ω–∞—Å–∫–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
- **–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è** - —Å–∏–ª–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
- **–í—ã–±—Ä–æ—Å—ã** - –Ω–µ—Ç–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Ç—Ä–µ–±—É—é—â–∏–µ –≤–Ω–∏–º–∞–Ω–∏—è 