# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã üöÄ

> [[bayesian-statistics|‚Üê –ë–∞–π–µ—Å–æ–≤—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞]] | [[README|–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ]] | [[survival-analysis|–ê–Ω–∞–ª–∏–∑ –≤—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏ ‚Üí]]

## üéØ –ß—Ç–æ –∏–∑—É—á–∏–º

- **ANOVA** - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø
- **–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑** - –ø–æ–∏—Å–∫ —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤  
- **–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏** - —É–ø—Ä–æ—â–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã** - —Å–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

---

## 1. –î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (ANOVA)

```python
class ANOVA:
    @staticmethod
    def one_way_anova(groups):
        """–û–¥–Ω–æ—Ñ–∞–∫—Ç–æ—Ä–Ω—ã–π –¥–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        import math
        
        k = len(groups)
        n_total = sum(len(group) for group in groups)
        grand_mean = sum(sum(group) for group in groups) / n_total
        
        # –°—É–º–º—ã –∫–≤–∞–¥—Ä–∞—Ç–æ–≤
        ss_between = sum(len(group) * (sum(group)/len(group) - grand_mean)**2 for group in groups)
        ss_within = sum(sum((x - sum(group)/len(group))**2 for x in group) for group in groups)
        
        # F-—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        ms_between = ss_between / (k - 1)
        ms_within = ss_within / (n_total - k)
        f_stat = ms_between / ms_within if ms_within > 0 else float('inf')
        
        p_value = 0.001 if f_stat > 6 else 0.01 if f_stat > 4 else 0.05 if f_stat > 3 else 0.1
        
        return {
            'f_statistic': f_stat,
            'p_value': p_value,
            'significant': p_value < 0.05,
            'interpretation': f"{'–ó–Ω–∞—á–∏–º—ã–µ' if p_value < 0.05 else '–ù–µ–∑–Ω–∞—á–∏–º—ã–µ'} —Ä–∞–∑–ª–∏—á–∏—è (F={f_stat:.2f})"
        }

# –ü—Ä–∏–º–µ—Ä: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–æ–≤
server_response_times = [
    [120, 115, 125, 118, 122],  # –°–µ—Ä–≤–µ—Ä A
    [110, 108, 112, 109, 113],  # –°–µ—Ä–≤–µ—Ä B  
    [130, 128, 132, 129, 133]   # –°–µ—Ä–≤–µ—Ä C
]

result = ANOVA.one_way_anova(server_response_times)
print(f"ANOVA: {result['interpretation']}")
print(f"P-value: {result['p_value']:.3f}")
```

---

## 2. –ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑

```python
class SimpleKMeans:
    @staticmethod
    def kmeans(data, k, max_iter=50):
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π k-means"""
        import random
        import math
        
        random.seed(42)
        n = len(data)
        
        # –°–ª—É—á–∞–π–Ω—ã–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã
        centroids = [data[random.randint(0, n-1)][:] for _ in range(k)]
        
        for _ in range(max_iter):
            # –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ –∫ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
            clusters = [[] for _ in range(k)]
            for point in data:
                distances = [math.sqrt(sum((a-b)**2 for a,b in zip(point, centroid))) 
                           for centroid in centroids]
                closest = distances.index(min(distances))
                clusters[closest].append(point)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤
            new_centroids = []
            for cluster in clusters:
                if cluster:
                    center = [sum(dim) / len(cluster) for dim in zip(*cluster)]
                    new_centroids.append(center)
                else:
                    new_centroids.append(centroids[len(new_centroids)])
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if all(math.sqrt(sum((a-b)**2 for a,b in zip(old, new))) < 0.001 
                   for old, new in zip(centroids, new_centroids)):
                break
            
            centroids = new_centroids
        
        return {'centroids': centroids, 'clusters': clusters}

# –ü—Ä–∏–º–µ—Ä: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
users = [
    [2.1, 1.8],   # –≤—Ä–µ–º—è –Ω–∞ —Å–∞–π—Ç–µ, —Å—Ç—Ä–∞–Ω–∏—Ü –∑–∞ —Å–µ—Å—Å–∏—é
    [2.3, 2.1], [1.8, 1.5],     # –æ–±—ã—á–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    [5.2, 8.1], [4.8, 7.5],     # –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏  
    [0.5, 1.2], [0.3, 0.8]      # –±—ã—Å—Ç—Ä–æ —É—à–µ–¥—à–∏–µ
]

clustering = SimpleKMeans.kmeans(users, k=3)
print("–ö–ª–∞—Å—Ç–µ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:")
for i, centroid in enumerate(clustering['centroids']):
    cluster_size = len(clustering['clusters'][i])
    print(f"–ì—Ä—É–ø–ø–∞ {i+1}: {centroid[0]:.1f}—á, {centroid[1]:.1f} —Å—Ç—Ä–∞–Ω–∏—Ü (—Ä–∞–∑–º–µ—Ä: {cluster_size})")
```

---

## 3. –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (PCA)

```python
class SimplePCA:
    @staticmethod
    def pca_2d(data):
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π PCA –¥–ª—è 2D –¥–∞–Ω–Ω—ã—Ö"""
        import math
        
        n = len(data)
        
        # –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
        mean_x = sum(point[0] for point in data) / n
        mean_y = sum(point[1] for point in data) / n
        centered = [[x - mean_x, y - mean_y] for x, y in data]
        
        # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        cov_xx = sum(x*x for x, y in centered) / (n-1)
        cov_yy = sum(y*y for x, y in centered) / (n-1)  
        cov_xy = sum(x*y for x, y in centered) / (n-1)
        
        # –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (2x2 –º–∞—Ç—Ä–∏—Ü–∞)
        trace = cov_xx + cov_yy
        det = cov_xx * cov_yy - cov_xy**2
        lambda1 = (trace + math.sqrt(trace**2 - 4*det)) / 2
        lambda2 = (trace - math.sqrt(trace**2 - 4*det)) / 2
        
        # –û–±—ä—è—Å–Ω–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
        total_var = lambda1 + lambda2
        explained_var = [lambda1/total_var, lambda2/total_var] if total_var > 0 else [0.5, 0.5]
        
        return {
            'explained_variance_ratio': explained_var,
            'cumulative_variance': [explained_var[0], explained_var[0] + explained_var[1]]
        }

# –ü—Ä–∏–º–µ—Ä: –∞–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
performance_metrics = [
    [95, 120], [80, 110], [90, 115],    # CPU%, RAM%
    [70, 100], [85, 105], [92, 118]
]

pca_result = SimplePCA.pca_2d(performance_metrics)
print("PCA –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
print(f"PC1 –æ–±—ä—è—Å–Ω—è–µ—Ç {pca_result['explained_variance_ratio'][0]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
print(f"PC2 –æ–±—ä—è—Å–Ω—è–µ—Ç {pca_result['explained_variance_ratio'][1]:.1%} –¥–∏—Å–ø–µ—Ä—Å–∏–∏")
print(f"–°—É–º–º–∞—Ä–Ω–æ: {pca_result['cumulative_variance'][1]:.1%}")
```

---

## 4. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤

```python
class TimeSeriesAdvanced:
    @staticmethod  
    def seasonal_decomposition(data, period=12):
        """–°–µ–∑–æ–Ω–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è"""
        n = len(data)
        
        # –¢—Ä–µ–Ω–¥ (—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ)
        trend = []
        half_period = period // 2
        
        for i in range(n):
            if i < half_period or i >= n - half_period:
                trend.append(sum(data) / n)  # –û–±—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –∫—Ä–∞–µ–≤
            else:
                window = data[i-half_period:i+half_period+1]
                trend.append(sum(window) / len(window))
        
        # –°–µ–∑–æ–Ω–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
        seasonal_sums = [0] * period
        seasonal_counts = [0] * period
        
        for i in range(n):
            detrended = data[i] - trend[i]
            season_idx = i % period
            seasonal_sums[season_idx] += detrended
            seasonal_counts[season_idx] += 1
        
        seasonal_pattern = [s/c if c > 0 else 0 for s, c in zip(seasonal_sums, seasonal_counts)]
        seasonal = [seasonal_pattern[i % period] for i in range(n)]
        
        # –û—Å—Ç–∞—Ç–∫–∏
        residual = [data[i] - trend[i] - seasonal[i] for i in range(n)]
        
        return {
            'trend': trend,
            'seasonal': seasonal, 
            'residual': residual,
            'seasonal_pattern': seasonal_pattern
        }
    
    @staticmethod
    def detect_anomalies(data, threshold=2):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ Z-score"""
        import math
        
        mean_val = sum(data) / len(data)
        variance = sum((x - mean_val)**2 for x in data) / (len(data) - 1)
        std_val = math.sqrt(variance)
        
        anomalies = []
        for i, value in enumerate(data):
            z_score = (value - mean_val) / std_val if std_val > 0 else 0
            if abs(z_score) > threshold:
                anomalies.append({
                    'index': i,
                    'value': value,
                    'z_score': z_score,
                    'type': '–≤—ã—Å–æ–∫–∞—è' if z_score > 0 else '–Ω–∏–∑–∫–∞—è'
                })
        
        return anomalies

# –ü—Ä–∏–º–µ—Ä: –∞–Ω–∞–ª–∏–∑ –º–µ—Å—è—á–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂
monthly_sales = [
    100, 95, 110, 120, 140, 160,      # H1
    180, 170, 150, 130, 120, 190,     # H2 (–ø–∏–∫ –≤ –¥–µ–∫–∞–±—Ä–µ)
    105, 100, 115, 125, 145, 165,     # H1 —Å–ª–µ–¥—É—é—â–µ–≥–æ –≥–æ–¥–∞
    185, 175, 155, 135, 125, 195      # H2
]

# –°–µ–∑–æ–Ω–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è
decomp = TimeSeriesAdvanced.seasonal_decomposition(monthly_sales, period=12)
print("–°–µ–∑–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–∞–∂:")

max_seasonal = max(decomp['seasonal_pattern'])
min_seasonal = min(decomp['seasonal_pattern'])
peak_month = decomp['seasonal_pattern'].index(max_seasonal) + 1
low_month = decomp['seasonal_pattern'].index(min_seasonal) + 1

print(f"–ü–∏–∫–æ–≤—ã–π –º–µ—Å—è—Ü: {peak_month} (+{max_seasonal:.1f})")
print(f"–°–ª–∞–±—ã–π –º–µ—Å—è—Ü: {low_month} ({min_seasonal:.1f})")

# –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π
anomalies = TimeSeriesAdvanced.detect_anomalies(monthly_sales)
if anomalies:
    print(f"\n–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π:")
    for anomaly in anomalies:
        print(f"  –ú–µ—Å—è—Ü {anomaly['index']+1}: {anomaly['value']} ({anomaly['type']} –∞–Ω–æ–º–∞–ª–∏—è)")
```

---

## üìö –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

### üîß –í —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ
- **ANOVA**: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
- **–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è**: –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –ø–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π
- **PCA**: –°–∂–∞—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### üìä –í –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ
- **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã**: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏
- **–ê–Ω–æ–º–∞–ª–∏–∏**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
- **–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å**: –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤

---

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã

- [[statistical-tests|–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã]] - –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã
- [[time-series|–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã]] - –æ—Å–Ω–æ–≤—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–Ω–∞–º–∏–∫–∏
- [[practical-applications|–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è]] - —Ä–µ–∞–ª—å–Ω—ã–µ –∫–µ–π—Å—ã

---

## üí° –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

- **–í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞**: –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –ø–æ–¥—Ö–æ–¥
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**: –ü–µ—Ä–µ–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –±–∏–∑–Ω–µ—Å-—Ä–µ—à–µ–Ω–∏—è
- **–í–∞–ª–∏–¥–∞—Ü–∏—è**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏–π –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –º–µ—Ç–æ–¥–æ–≤

> üöÄ **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã**: –ú–æ—â–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á! 